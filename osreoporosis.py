# -*- coding: utf-8 -*-
"""osreoporosis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KBk2XZfLD9B2CyGMARyGhUS7BhKNwCby
"""

# Importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Preprocessing and modeling
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, make_scorer
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler

# Suppressing warnings
import warnings
warnings.filterwarnings("ignore")

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/DataSets/Osteoporosis Risk Prediction/osteoporosis.csv')
df.head()

df.shape

df.info

colums_with_missing_values = df.columns[df.isnull().any()]

print('Missing values percentage ')
for columns in colums_with_missing_values:
    print(columns,':',df[columns].isnull().sum()/df.shape[0]*100)

df.fillna('None',inplace=True)

df = df.drop(['Id'], axis=1)

categorical_colums = df.select_dtypes(include=['object']).columns
for columns in categorical_colums:
    print(df[columns].value_counts())

df.describe()

df.head()

plt.figure(figsize=(5,5))
df['Osteoporosis'].value_counts().plot.pie(autopct='%1.1f%%').set_title('Osteoporosis');

plt.figure(figsize=(10,5))
df[df['Osteoporosis']==1]['Age'].plot.hist(bins=30, alpha=0.5, color='blue', label='Yes')
df[df['Osteoporosis']==0]['Age'].plot.hist(bins=30, alpha=0.5, color='red', label='No')

plt.legend()
plt.xlabel('Age')
plt.ylabel('Osteoporosis by Age')

sns.countplot(x='Gender', data=df, hue='Osteoporosis').set_title('Gender vs Osteoporosis')

sns.countplot(x='Hormonal Changes', data=df, hue='Osteoporosis').set_title('Hormonal Changes vs Osteoporosis')

sns.countplot(x='Family History', data=df, hue='Osteoporosis').set_title('Family History vs Osteoporosis')

sns.countplot(x='Race/Ethnicity', data=df, hue='Osteoporosis').set_title('Race/Ethnicity vs Osteoporosis')

sns.countplot(x='Body Weight', data=df, hue='Osteoporosis').set_title('Body Weighty vs Osteoporosis')

fig,ax =plt.subplots(1, 2, figsize=(20,6))
sns.countplot(x='Calcium Intake', data=df , ax=ax[0], hue='Osteoporosis').set_title('Calcium Intake and Osteoporosis')
sns.countplot(x='Vitamin D Intake', data=df , ax=ax[1], hue='Osteoporosis').set_title('Vitamin D Intake and Osteoporosis')

sns.countplot(x='Physical Activity', data=df, hue='Osteoporosis').set_title('Physical Activity vs Osteoporosis')

fig,ax =plt.subplots(1, 2, figsize=(20,6))
sns.countplot(x='Smoking', data=df , ax=ax[0], hue='Osteoporosis').set_title('Smoking and Osteoporosis')
sns.countplot(x='Alcohol Consumption', data=df , ax=ax[1], hue='Osteoporosis').set_title('Alcohol Consumption and Osteoporosis')

fig,ax =plt.subplots(1, 2, figsize=(20,6))
sns.countplot(x='Medical Conditions', data=df , ax=ax[0], hue='Osteoporosis').set_title('Medical Conditions and Osteoporosis')
sns.countplot(x='Medications', data=df , ax=ax[1], hue='Osteoporosis').set_title('Medications  and Osteoporosis')

sns.countplot(x='Prior Fractures', data=df, hue='Osteoporosis').set_title('Prior Fractures 	 vs Osteoporosis')

cols = df.select_dtypes(include=['object']).columns

le = LabelEncoder()

for col in cols:
    df[col] = le.fit_transform(df[col])
    print(col,':',df[col].unique())

plt.figure(figsize=(20,20))
sns.heatmap(df.corr(), annot=True)

X = df.drop(columns='Osteoporosis', axis=1)
y = df['Osteoporosis']
X_train , X_test , y_train, y_test = train_test_split(X , y, test_size=0.2, random_state=42)
X_train , X_val ,y_train , y_val = train_test_split(X_train, y_train , test_size=0.2 , random_state=42)

logestic_model= LogisticRegression()
logestic_model.fit(X_train, y_train)

X_train_predict = logestic_model.predict(X_train)

training = accuracy_score(y_train, X_train_predict)

print(training)

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model_rand = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(model_rand,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model_rand = RandomForestClassifier(criterion='gini',n_estimators=250 , random_state=42, max_depth=10, min_samples_leaf=2, min_samples_split=2)
model_rand.fit(X_train,y_train)
y_perd = model_rand.predict(X_test)
accuracy = accuracy_score(y_test,y_perd)
precision = precision_score(y_test,y_perd)
recall = recall_score(y_test,y_perd)
f1 = f1_score(y_test,y_perd)
score = model_rand.score(X_train,y_train)
print(f'Accuracy :  {accuracy:.2f}%')
print(f'precision :  {precision:.2f}%')
print(f'recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from sklearn.svm import SVC
model = SVC(kernel='linear', random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train,y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model = AdaBoostClassifier(random_state=42)
grid_search = GridSearchCV(model,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model = AdaBoostClassifier(n_estimators=200, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train,y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

!pip install catboost

from catboost import CatBoostClassifier

model = CatBoostClassifier(n_estimators=300, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train,y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from xgboost import XGBClassifier

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model_rand = XGBClassifier(random_state=42)
grid_search = GridSearchCV(model_rand,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model = XGBClassifier(n_estimators=350, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train,y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from sklearn.ensemble import GradientBoostingClassifier

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model_rand = GradientBoostingClassifier(random_state=42)
grid_search = GridSearchCV(model_rand,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model = GradientBoostingClassifier(n_estimators=100, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train, y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from lightgbm import LGBMClassifier

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model_rand = LGBMClassifier(random_state=42)
grid_search = GridSearchCV(model_rand,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model = LGBMClassifier(n_estimators=100,  random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train, y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from sklearn.metrics import roc_curve, auc

models = [
    RandomForestClassifier(criterion='gini',n_estimators=250 , random_state=42, max_depth=10, min_samples_leaf=2, min_samples_split=2),
    AdaBoostClassifier(n_estimators=200, random_state=42),
    SVC(kernel='linear', probability=True, random_state=42),
    CatBoostClassifier(n_estimators=300, random_state=42, verbose=False),
    XGBClassifier(n_estimators=350, random_state=42),
    LogisticRegression(),
    GradientBoostingClassifier(n_estimators=100, random_state=42),
    LGBMClassifier(n_estimators=100,  random_state=42)


]
# Plot ROC curve for each model

plt.figure(figsize=(10, 8))
for model in models:
    model.fit(X_train, y_train)
    y_score = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_score)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label='%s (AUC = %0.2f)' % (type(model).__name__, roc_auc))

plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)
plt.show();

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler
from tensorflow.keras.regularizers import l1_l2

# Assuming X and y are your feature and target matrices

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define advanced neural network architecture
model = Sequential([
    Dense(512, input_dim=X_train_scaled.shape[1]),
    BatchNormalization(),
    LeakyReLU(alpha=0.1),
    Dropout(0.2),
    Dense(256, kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),
    BatchNormalization(),
    LeakyReLU(alpha=0.1),
    Dropout(0.2),
    Dense(128, kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),
    BatchNormalization(),
    LeakyReLU(alpha=0.1),
    Dropout(0.2),
    Dense(64, kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),
    BatchNormalization(),
    LeakyReLU(alpha=0.1),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

# Define custom learning rate scheduler
def lr_scheduler(epoch, lr):
    if epoch % 10 == 0 and epoch != 0:
        lr = lr * 0.9
    return lr

# Compile the model with Adam optimizer and custom learning rate scheduler
optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)
model.compile(optimizer=optimizer,
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Define early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Define learning rate scheduler callback
lr_scheduler_callback = LearningRateScheduler(lr_scheduler)

# Train the model with early stopping and learning rate scheduler callbacks
history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64,
                    validation_split=0.2, callbacks=[early_stopping, lr_scheduler_callback], verbose=1)

# Evaluate the model
y_pred_prob = model.predict(X_test_scaled).ravel()
y_pred = (y_pred_prob > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

# Plot ROC curve
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# Plot training history
plt.figure(figsize=(8, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, ParameterGrid, KFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler
from tensorflow.keras.regularizers import l1_l2
from tensorflow.keras.optimizers import legacy

# Assuming X and y are defined as your input features and target variable

# Split data into train, validation, and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Define advanced neural network architecture
def create_model(optimizer=legacy.Adam(), dropout_rate=0.2, l1_reg=0.01, l2_reg=0.01):
    model = Sequential()
    model.add(Dense(128, input_dim=X_train_scaled.shape[1], kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.1))
    model.add(Dropout(dropout_rate))
    model.add(Dense(64, kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.1))
    model.add(Dropout(dropout_rate))
    model.add(Dense(32, kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.1))
    model.add(Dropout(dropout_rate))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Learning rate scheduler
def lr_scheduler(epoch, lr):
    if epoch % 10 == 0 and epoch > 0:
        lr = lr * 0.9
    return lr

# Hyperparameter tuning with k-fold cross-validation
param_grid = {'optimizer': [legacy.Adam(), legacy.RMSprop()], 'dropout_rate': [0.2, 0.3, 0.4], 'l1_reg': [0.01, 0.001], 'l2_reg': [0.01, 0.001]}
kf = KFold(n_splits=5, shuffle=True, random_state=42)

best_scores = []
best_models = []

for train_index, val_index in kf.split(X_train_scaled):
    X_train_kf, X_val_kf = X_train_scaled[train_index], X_train_scaled[val_index]
    y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]

    models = []
    scores = []

    for params in ParameterGrid(param_grid):
        model = create_model(**params)
        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
        lr_scheduler_callback = LearningRateScheduler(lr_scheduler)
        history = model.fit(X_train_kf, y_train_kf, epochs=100, validation_data=(X_val_kf, y_val_kf), callbacks=[early_stopping, lr_scheduler_callback], verbose=0)
        scores.append(max(history.history['val_accuracy']))
        models.append(model)

    best_model_index = np.argmax(scores)
    best_models.append(models[best_model_index])
    best_scores.append(scores[best_model_index])

best_model_index = np.argmax(best_scores)
best_model = best_models[best_model_index]
print('Best model index:', best_model_index)

# Evaluate the best model
y_pred_prob = best_model.predict(X_test_scaled)
y_pred = (y_pred_prob > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
