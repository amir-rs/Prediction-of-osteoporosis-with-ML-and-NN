# -*- coding: utf-8 -*-
"""osreoporosis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KBk2XZfLD9B2CyGMARyGhUS7BhKNwCby
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder , StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score , precision_score , recall_score , f1_score , confusion_matrix , make_scorer
from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv('osteoporosis.csv')
df.head()

df.shape

df.info

colums_with_missing_values = df.columns[df.isnull().any()]

print('Missing values percentage ')
for columns in colums_with_missing_values:
    print(columns,':',df[columns].isnull().sum()/df.shape[0]*100)

df.fillna('None',inplace=True)

df = df.drop(['Id'], axis=1)

categorical_colums = df.select_dtypes(include=['object']).columns
for columns in categorical_colums:
    print(df[columns].value_counts())

df.describe()

df.head()

plt.figure(figsize=(5,5))
df['Osteoporosis'].value_counts().plot.pie(autopct='%1.1f%%').set_title('Osteoporosis');

plt.figure(figsize=(10,5))
df[df['Osteoporosis']==1]['Age'].plot.hist(bins=30, alpha=0.5, color='blue', label='Yes')
df[df['Osteoporosis']==0]['Age'].plot.hist(bins=30, alpha=0.5, color='red', label='No')

plt.legend()
plt.xlabel('Age')
plt.ylabel('Osteoporosis by Age')

sns.countplot(x='Gender', data=df, hue='Osteoporosis').set_title('Gender vs Osteoporosis')

sns.countplot(x='Hormonal Changes', data=df, hue='Osteoporosis').set_title('Hormonal Changes vs Osteoporosis')

sns.countplot(x='Family History', data=df, hue='Osteoporosis').set_title('Family History vs Osteoporosis')

sns.countplot(x='Race/Ethnicity', data=df, hue='Osteoporosis').set_title('Race/Ethnicity vs Osteoporosis')

sns.countplot(x='Body Weight', data=df, hue='Osteoporosis').set_title('Body Weighty vs Osteoporosis')

fig,ax =plt.subplots(1, 2, figsize=(20,6))
sns.countplot(x='Calcium Intake', data=df , ax=ax[0], hue='Osteoporosis').set_title('Calcium Intake and Osteoporosis')
sns.countplot(x='Vitamin D Intake', data=df , ax=ax[1], hue='Osteoporosis').set_title('Vitamin D Intake and Osteoporosis')

sns.countplot(x='Physical Activity', data=df, hue='Osteoporosis').set_title('Physical Activity vs Osteoporosis')

fig,ax =plt.subplots(1, 2, figsize=(20,6))
sns.countplot(x='Smoking', data=df , ax=ax[0], hue='Osteoporosis').set_title('Smoking and Osteoporosis')
sns.countplot(x='Alcohol Consumption', data=df , ax=ax[1], hue='Osteoporosis').set_title('Alcohol Consumption and Osteoporosis')

fig,ax =plt.subplots(1, 2, figsize=(20,6))
sns.countplot(x='Medical Conditions', data=df , ax=ax[0], hue='Osteoporosis').set_title('Medical Conditions and Osteoporosis')
sns.countplot(x='Medications', data=df , ax=ax[1], hue='Osteoporosis').set_title('Medications  and Osteoporosis')

sns.countplot(x='Prior Fractures', data=df, hue='Osteoporosis').set_title('Prior Fractures 	 vs Osteoporosis')

cols = df.select_dtypes(include=['object']).columns

le = LabelEncoder()

for col in cols:
    df[col] = le.fit_transform(df[col])
    print(col,':',df[col].unique())

plt.figure(figsize=(20,20))
sns.heatmap(df.corr(), annot=True)

X = df.drop(columns='Osteoporosis', axis=1)
y = df['Osteoporosis']
X_train , X_test , y_train, y_test = train_test_split(X , y, test_size=0.2, random_state=42)
X_train , X_val ,y_train , y_val = train_test_split(X_train, y_train , test_size=0.2 , random_state=42)

logestic_model= LogisticRegression()
logestic_model.fit(X_train, y_train)

X_train_predict = logestic_model.predict(X_train)

training = accuracy_score(y_train, X_train_predict)

print(training)

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model_rand = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(model_rand,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model_rand = RandomForestClassifier(criterion='gini',n_estimators=250 , random_state=42, max_depth=10, min_samples_leaf=2, min_samples_split=2)
model_rand.fit(X_train,y_train)
y_perd = model_rand.predict(X_test)
accuracy = accuracy_score(y_test,y_perd)
precision = precision_score(y_test,y_perd)
recall = recall_score(y_test,y_perd)
f1 = f1_score(y_test,y_perd)
score = model_rand.score(X_train,y_train)
print(f'Accuracy :  {accuracy:.2f}%')
print(f'precision :  {precision:.2f}%')
print(f'recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# Determine the number of hidden layers and neurons to test
hidden_layers = [1, 2, 3, 4]  # The number of hidden layers
neurons =[16, 32, 64, 128]  # The number of neurons in each layer

best_accuracy = 0
best_model = None

for num_layers in hidden_layers:
    for num_neurons in neurons:
        # creat model
        model = Sequential()
        model.add(Dense(num_neurons, activation='relu', input_shape=(X_train.shape[1],)))
        for _ in range(num_layers - 1):
            model.add(Dense(num_neurons, activation='relu'))
            model.add(Dropout(0.2))
        model.add(Dense(1, activation='sigmoid'))

        # compile model
        model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

        # train model
        history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=0)

        # metrics accuracy
        y_pred_prob = model.predict(X_test)
        y_pred = (y_pred_prob > 0.5).astype(int)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"Neural Network Accuracy with {num_layers} layers and {num_neurons} neurons: {accuracy}")
        #save best model
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_model = model

print("Best Neural Network Accuracy:", best_accuracy)

train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
epochs = range(1, len(train_accuracy) + 1)
plt.plot(epochs, train_accuracy, 'b', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')
plt.title('Training and Validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

from sklearn.svm import SVC
model = SVC(kernel='linear', random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train,y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model = AdaBoostClassifier(random_state=42)
grid_search = GridSearchCV(model,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model = AdaBoostClassifier(n_estimators=200, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train,y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

!pip install catboost

from catboost import CatBoostClassifier

model = CatBoostClassifier(n_estimators=300, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train,y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from xgboost import XGBClassifier

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model_rand = XGBClassifier(random_state=42)
grid_search = GridSearchCV(model_rand,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model = XGBClassifier(n_estimators=350, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train,y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from sklearn.ensemble import GradientBoostingClassifier

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model_rand = GradientBoostingClassifier(random_state=42)
grid_search = GridSearchCV(model_rand,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model = GradientBoostingClassifier(n_estimators=100, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train, y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from lightgbm import LGBMClassifier

param_grid = {'n_estimators': [100,200,250,300,350,400,500]}
model_rand = LGBMClassifier(random_state=42)
grid_search = GridSearchCV(model_rand,param_grid,cv=5,scoring='accuracy')
grid_search.fit(X_train,y_train)
print('grid search reasult:')
print('best parameters : ', grid_search.best_params_)
print('best cross-validated accuracy: ',grid_search.best_score_)

model = LGBMClassifier(n_estimators=100,  random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
score = model.score(X_train, y_train)

print(f'Accuracy :  {accuracy:.2f}%')
print(f'Precision :  {precision:.2f}%')
print(f'Recall :  {recall:.2f}%')
print(f'F1 score :  {f1:.2f}%')
print(f'score :  {score:.2f}%')

from sklearn.metrics import roc_curve, auc

models = [
    RandomForestClassifier(criterion='gini',n_estimators=250 , random_state=42, max_depth=10, min_samples_leaf=2, min_samples_split=2),
    AdaBoostClassifier(n_estimators=200, random_state=42),
    SVC(kernel='linear', probability=True, random_state=42),
    CatBoostClassifier(n_estimators=300, random_state=42, verbose=False),
    XGBClassifier(n_estimators=350, random_state=42),
    LogisticRegression(),
    GradientBoostingClassifier(n_estimators=100, random_state=42),
    LGBMClassifier(n_estimators=100,  random_state=42)


]
# Plot ROC curve for each model

plt.figure(figsize=(10, 8))
for model in models:
    model.fit(X_train, y_train)
    y_score = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_score)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label='%s (AUC = %0.2f)' % (type(model).__name__, roc_auc))

plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)
plt.show();

